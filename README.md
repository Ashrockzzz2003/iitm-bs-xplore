# IITM BS Xplore

## Problem Statement

-   Students face difficulty planning academic progression (which courses to take according to prerequisite requirements, academic goals, number of terms in which they wish to complete the program).
-   Information is spread across websites, student handbooks, grading documents, and other PDFs.

âœ¦ Similar challenges exist in most universities and online education platforms where course structures are complex and requirements vary.

---

## Target Users

-   Students enrolled in the online program
-   Academic advisors/staff assisting students with course planning
-   Prospective learners exploring program requirements

âœ¦ Can extend to learners across MOOCs, degree programs, or professional certifications.

---

## Feasibility & Data Sources

-   **IITM online degree website**: Academics page, Course pages, NPTEL website for electives
-   **Documents**: Grading document, Student handbook
-   **Control UI**: Allows staff to configure additional URLs/PDFs

âœ¦ Generic sources: University/college/MOOC websites, program brochures, policy handbooks.

### Data Sources List

#### DS

-   [https://study.iitm.ac.in/ds/academics.html\#AC1](https://study.iitm.ac.in/ds/academics.html#AC1)
    -   All course subpages linked in this page
    -   Pattern \- [https://study.iitm.ac.in/ds/course_pages/{course_id}.html](https://study.iitm.ac.in/ds/course_pages/BSSE2001.html)
-   [https://study.iitm.ac.in/ds/admissions.html\#AD0](https://study.iitm.ac.in/ds/admissions.html#AD0)
-   Student Handbook \- link sourced from [acegrade.in](http://acegrade.in)
    -   [https://docs.google.com/document/u/1/d/e/2PACX-1vRxGnnDCVAO3KX2CGtMIcJQuDrAasVk2JHbDxkjsGrTP5ShhZK8N6ZSPX89lexKx86QPAUswSzGLsOA/pub](https://docs.google.com/document/u/1/d/e/2PACX-1vRxGnnDCVAO3KX2CGtMIcJQuDrAasVk2JHbDxkjsGrTP5ShhZK8N6ZSPX89lexKx86QPAUswSzGLsOA/pub)
-   Grading Policy \- link sourced from [acegrade.in](http://acegrade.in)
    -   [https://docs.google.com/document/u/1/d/e/2PACX-1vRKOWaLjxsts3qAM4h00EDvlB-GYRSPqqVXTfq3nGWFQBx91roxcU1qGv2ksS7jT4EQPNo8Rmr2zaE9/pub\#h.cbcq4ial1xkk](https://docs.google.com/document/u/1/d/e/2PACX-1vRKOWaLjxsts3qAM4h00EDvlB-GYRSPqqVXTfq3nGWFQBx91roxcU1qGv2ksS7jT4EQPNo8Rmr2zaE9/pub#h.cbcq4ial1xkk)

#### ES

-   [https://study.iitm.ac.in/es/academics.html\#AC1](https://study.iitm.ac.in/es/academics.html#AC1)
    -   All course subpages linked in this page
    -   Pattern \- [https://study.iitm.ac.ine/es/course_pages/{course_id}.html](https://study.iitm.ac.ine/es/course_pages/{course_id}.html)
-   [https://study.iitm.ac.in/es/admissions.html\#AD0](https://study.iitm.ac.in/es/admissions.html#AD0)
-   [https://study.iitm.ac.in/es/inthemedia.html](https://study.iitm.ac.in/es/inthemedia.html)
-   [https://study.iitm.ac.in/es/archive.html](https://study.iitm.ac.in/es/archive.html)
-   [https://study.iitm.ac.in/es/faq.html](https://study.iitm.ac.in/es/faq.html)
-   Similarly other links for ES

#### Anonymous

-   [https://study.iitm.ac.in/ds/student_life.html](https://study.iitm.ac.in/ds/student_life.html)
-   [https://paradox-showcase.web.app/](https://paradox-showcase.web.app/)
-   [https://study.iitm.ac.in/student-achievements/interns](https://study.iitm.ac.in/student-achievements/interns)
-   [https://study.iitm.ac.in/ds/testimonials.html](https://study.iitm.ac.in/ds/testimonials.html)
-   [https://study.iitm.ac.in/student-achievements/toppers](https://study.iitm.ac.in/student-achievements/toppers)
-   [https://study.iitm.ac.in/student-achievements/projects](https://study.iitm.ac.in/student-achievements/projects)
-   Docs listed in
    -   [https://study.iitm.ac.in/ds/archive.html](https://study.iitm.ac.in/ds/archive.html)
-   [https://study.iitm.ac.in/ds/aboutIITM.html](https://study.iitm.ac.in/ds/aboutIITM.html)
-   Future
    -   [https://bsinsider.in/](https://bsinsider.in/)
    -   [https://podgoodies.iitmadrasonline.in/](https://podgoodies.iitmadrasonline.in/)
-   Any Additional PDF docs can be added through Control UI by authorized personnel.

---

## Existing Solutions & Limitations

-   Dedicated sessions for course selection and orientation sessions for different courses
-   Scattered information across websites & documents

âœ¦ Existing university chatbots are often FAQ/rule-based and lack personalization or academic planning capability.

---

## Proposed Solution

A **scraper** to extract structured/unstructured data from websites & documents.

### Approach I: KG + RAG based pipeline

-   **Knowledge Graph (KG)** will store rules: Course prerequisites, Credit requirements for any level, Course mapping to levels, Compulsory courses per level
-   **Retrieval Augmented Generation (RAG)** will store unstructured descriptive context about a course or topic.

### Approach II: Multi-Agent Orchestration

Each agent will have its own responsibility:

-   **Data Agent** â€“ Fetch info about a particular course or topic
-   **Validation Agent** â€“ Check prerequisites for a course
-   **Recommendation Agent** â€“ Suggest courses/paths

### UI for Students

Natural language query interface, e.g.:

-   _"I have completed 2 courses (X & Y) of the diploma level (DS) and plan to complete my diploma in the next 2 terms. Which courses should I take next term that continue from X & Y?"_
-   _"I have already completed the Deep Learning course and want to do some hands-on work. Which elective course would best help me with this?"_

### Control UI for Staff

-   Manage/update data sources dynamically
-   Add new sources (websites, PDFs, brochures)

âœ¦ **Generic applicability**: The same pipeline can be applied to any academic institution or program.

---

## ðŸš€ Current Implementation Status

### âœ… Completed Features

-   **Daily Data Pipeline**: Automated scraping of 127+ IITM DS/ES pages with 7+ lakh characters of content
-   **Hierarchical Text Organization**: Content organized by program and level (ds/{level}/content.txt, es/{level}/content.txt)
-   **ChromaDB RAG Pipeline**: Vector embeddings using Google Gemini for semantic search across 50k-2L character collections
-   **Multi-Agent AI System**: Google ADK-based agents with ChromaDB integration for RAG capabilities
-   **Complete DS Agent Suite**: All three DS agents implemented (Foundation, Diploma, Degree levels)
-   **Enhanced ChromaDB Tools**: Advanced querying capabilities with smart_query, program/level filtering, and metadata support
-   **Chunked Data Processing**: Improved retrieval precision with chunked content and similarity scoring
-   **Agent Orchestration Framework**: Architecture for sub-agents and orchestrator agent routing

### ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IITM BS Xplore Pipeline                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚  Text Aggregation â”‚    â”‚  ChromaDB RAG   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ DS Academics  â”‚â”€â”€â”€â–¶â”‚ â€¢ 127+ pages     â”‚â”€â”€â”€â–¶â”‚ â€¢ Collections   â”‚
â”‚ â€¢ ES Academics  â”‚    â”‚ â€¢ 7L+ chars      â”‚    â”‚ â€¢ 50k-2L chars  â”‚
â”‚ â€¢ Course Pages  â”‚    â”‚ â€¢ Hierarchical   â”‚    â”‚ â€¢ Gemini Embed  â”‚
â”‚ â€¢ Daily Updates â”‚    â”‚ â€¢ Chunked Data   â”‚    â”‚ â€¢ Vector Search â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Agent System                              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Enhanced        â”‚    â”‚  DS Agent Suite â”‚    â”‚  Context     â”‚ â”‚
â”‚  â”‚ ChromaDB Tools  â”‚â”€â”€â”€â–¶â”‚                 â”‚    â”‚  Agent       â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚ â€¢ Foundation    â”‚    â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ smart_query   â”‚    â”‚ â€¢ Diploma       â”‚    â”‚ â€¢ Ask for    â”‚ â”‚
â”‚  â”‚ â€¢ Program/Level â”‚    â”‚ â€¢ Degree        â”‚    â”‚   Program    â”‚ â”‚
â”‚  â”‚ â€¢ Metadata      â”‚    â”‚ â€¢ Specialized   â”‚    â”‚ â€¢ Clarify    â”‚ â”‚
â”‚  â”‚ â€¢ Chunked Data  â”‚    â”‚   Knowledge     â”‚    â”‚   Level      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Web UI         â”‚    â”‚  Natural        â”‚    â”‚  Student     â”‚ â”‚
â”‚  â”‚  (Google ADK)   â”‚    â”‚  Language       â”‚    â”‚  Interface   â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚  Queries        â”‚    â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ Chat Interfaceâ”‚    â”‚                 â”‚    â”‚ â€¢ Course     â”‚ â”‚
â”‚  â”‚ â€¢ Real-time     â”‚    â”‚ â€¢ "What courses â”‚    â”‚   Planning   â”‚ â”‚
â”‚  â”‚   Responses     â”‚    â”‚   should I take â”‚    â”‚ â€¢ Prereq     â”‚ â”‚
â”‚  â”‚ â€¢ Context Aware â”‚    â”‚   next term?"   â”‚    â”‚   Validation â”‚ â”‚
â”‚  â”‚ â€¢ Multi-Agent   â”‚    â”‚ â€¢ Level-specificâ”‚    â”‚ â€¢ Academic   â”‚ â”‚
â”‚  â”‚   Routing       â”‚    â”‚   Queries       â”‚    â”‚   Guidance   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“ Chunking Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IITM BS Xplore Chunking Pipeline             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Content   â”‚    â”‚  Text Processing â”‚    â”‚  Chunking Logic â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ HTML Pages    â”‚â”€â”€â”€â–¶â”‚ â€¢ Clean HTML     â”‚â”€â”€â”€â–¶â”‚ â€¢ Split by Size â”‚
â”‚ â€¢ PDF Documents â”‚    â”‚ â€¢ Extract Text   â”‚    â”‚ â€¢ Split by Topicâ”‚
â”‚ â€¢ Course Pages  â”‚    â”‚ â€¢ Remove Noise   â”‚    â”‚ â€¢ Overlap Chunksâ”‚
â”‚ â€¢ 127+ Sources  â”‚    â”‚ â€¢ Normalize Text â”‚    â”‚ â€¢ Metadata Tags â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Chunked Content Storage                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chunk Metadata â”‚    â”‚  Content Chunks â”‚    â”‚  Embeddings  â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ Program (DS/ES)â”‚   â”‚ â€¢ 1000-2000     â”‚    â”‚ â€¢ Gemini     â”‚ â”‚
â”‚  â”‚ â€¢ Level         â”‚    â”‚   characters    â”‚    â”‚   Embeddings â”‚ â”‚
â”‚  â”‚ â€¢ Course ID     â”‚    â”‚ â€¢ Semantic      â”‚    â”‚ â€¢ 768 dims   â”‚ â”‚
â”‚  â”‚ â€¢ URL Source    â”‚    â”‚   boundaries    â”‚    â”‚ â€¢ Vector DB  â”‚ â”‚
â”‚  â”‚ â€¢ Chunk Index   â”‚    â”‚ â€¢ Overlap for   â”‚    â”‚ â€¢ Similarity â”‚ â”‚
â”‚  â”‚ â€¢ Timestamp     â”‚    â”‚   context       â”‚    â”‚   Search     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ChromaDB Collections                         â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DS Collections â”‚    â”‚  ES Collections â”‚    â”‚  Generic     â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚  Collections â”‚ â”‚
â”‚  â”‚ â€¢ ds_foundation â”‚    â”‚ â€¢ es_foundation â”‚    â”‚ â€¢ generic    â”‚ â”‚
â”‚  â”‚ â€¢ ds_diploma    â”‚    â”‚ â€¢ es_diploma    â”‚    â”‚ â€¢ main       â”‚ â”‚
â”‚  â”‚ â€¢ ds_degree     â”‚    â”‚ â€¢ es_degree     â”‚    â”‚ â€¢ shared     â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚              â”‚ â”‚
â”‚  â”‚ Each collection:â”‚    â”‚ Each collection:â”‚    â”‚ Cross-programâ”‚ â”‚
â”‚  â”‚ â€¢ 50k-200k charsâ”‚    â”‚ â€¢ 50k-200k charsâ”‚    â”‚   content    â”‚ â”‚
â”‚  â”‚ â€¢ 100-500 chunksâ”‚    â”‚ â€¢ 100-500 chunksâ”‚    â”‚ â€¢ Common     â”‚ â”‚
â”‚  â”‚ â€¢ Program-specificâ”‚  â”‚ â€¢ Program-specificâ”‚  â”‚   policies   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“ Project Structure

```
â”œâ”€â”€ xplorer/               # Data Pipeline & ChromaDB
â”‚   â”œâ”€â”€ util/
â”‚   â”‚   â”œâ”€â”€ chromadb/      # ChromaDB upload & query tools
â”‚   â”‚   â””â”€â”€ hierarchical_aggregator.py
â”‚   â”œâ”€â”€ outputs/           # Hierarchical content storage
â”‚   â”‚   â”œâ”€â”€ ds/            # Data Science program
â”‚   â”‚   â”‚   â”œâ”€â”€ foundation/content.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ diploma/content.txt
â”‚   â”‚   â”‚   â””â”€â”€ degree/content.txt
â”‚   â”‚   â””â”€â”€ es/            # Electronics Systems program
â”‚   â”‚       â”œâ”€â”€ foundation/content.txt
â”‚   â”‚       â”œâ”€â”€ diploma/content.txt
â”‚   â”‚       â””â”€â”€ degree/content.txt
â”‚   â””â”€â”€ app.py             # Main data pipeline
â”œâ”€â”€ ai/                    # Multi-Agent AI System
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ ds/            # Data Science Agents (Complete)
â”‚   â”‚   â”‚   â”œâ”€â”€ foundation/ # DS Foundation Level Agent âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ diploma/   # DS Diploma Level Agent âœ…
â”‚   â”‚   â”‚   â””â”€â”€ degree/    # DS Degree Level Agent âœ…
â”‚   â”‚   â”œâ”€â”€ es/            # Electronics Systems Agents (Planned)
â”‚   â”‚   â”‚   â”œâ”€â”€ foundation/ # ES Foundation Level Agent (planned)
â”‚   â”‚   â”‚   â”œâ”€â”€ diploma/   # ES Diploma Level Agent (planned)
â”‚   â”‚   â”‚   â””â”€â”€ degree/    # ES Degree Level Agent (planned)
â”‚   â”‚   â””â”€â”€ tools/         # Enhanced ChromaDB query tools
â”‚   â”‚       â””â”€â”€ chromadb_tools.py # Advanced querying capabilities
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ kg/                    # Legacy Knowledge Graph (paused)
    â””â”€â”€ ...                # Neo4j integration (not actively used)
```

**Key Features**: Daily data pipeline, hierarchical organization, ChromaDB RAG, Google ADK agents, orchestrated sub-agents

## ðŸš€ Quick Start

### 1. Data Pipeline & ChromaDB Setup

```bash
cd xplorer/
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Start ChromaDB server (in separate terminal)
chroma run --host localhost --port 8000

# Run daily data pipeline - scrapes 127+ pages and organizes hierarchically
python app.py
```

This will:

-   Scrape IITM DS/ES academics pages and all course pages
-   Parse and organize content into `outputs/ds/{level}/content.txt` and `outputs/es/{level}/content.txt`
-   Generate ChromaDB collections with Gemini embeddings for each content file
-   Process 7+ lakh characters across 127+ pages

### 2. AI Agents Setup

```bash
cd ai/
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Set environment variables in a .env file
echo "CHROMA_HOST=localhost" >> .env
echo "CHROMA_PORT=8000" >> .env
echo "GOOGLE_API_KEY=your_gemini_api_key" >> .env

# Run any of the available DS agents with web UI
cd agents/ds/foundation/  # For Foundation Level Agent
# OR
cd agents/ds/diploma/     # For Diploma Level Agent
# OR
cd agents/ds/degree/      # For Degree Level Agent

adk web
```

This will:

-   Start the selected DS agent (Foundation, Diploma, or Degree level)
-   Launch Google ADK web interface for testing
-   Enable natural language queries about the specific level
-   Provide context-aware responses using enhanced ChromaDB RAG
-   Access specialized knowledge for each academic level

### 3. Legacy Knowledge Graph (Optional)

```bash
cd kg/
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Parse single URLs (legacy approach - paused)
python app.py --url https://study.iitm.ac.in/ds/academics.html
```

## ðŸ”§ How It Works

### Daily Data Pipeline

1. **Web Scraping**: Automated scraping of IITM DS/ES academics pages and all course pages
2. **Content Parsing**: Extracts and cleans text content from 127+ pages
3. **Hierarchical Organization**: Organizes content by program and level:
    - `outputs/ds/foundation/content.txt` (Data Science Foundation)
    - `outputs/ds/diploma/content.txt` (Data Science Diploma)
    - `outputs/ds/degree/content.txt` (Data Science Degree)
    - `outputs/es/foundation/content.txt` (Electronics Systems Foundation)
    - `outputs/es/diploma/content.txt` (Electronics Systems Diploma)
    - `outputs/es/degree/content.txt` (Electronics Systems Degree)
4. **Content Processing**: Processes 7+ lakh characters across all levels

### ChromaDB RAG Pipeline

1. **Collection Creation**: Each content.txt file becomes a unique ChromaDB collection
2. **Vector Embeddings**: Uses Google Gemini `gemini-embedding-001` model for embeddings
3. **Collection Management**: Collections range from 50k to 2 lakh characters each
4. **Semantic Search**: Enables natural language queries across all content

### AI Agent System

1. **Sub-Agent Architecture**: Specialized agents for each program-level combination
2. **ChromaDB Integration**: Agents query relevant collections for context
3. **RAG Pipeline**: Retrieval-Augmented Generation for accurate, context-aware responses
4. **Orchestrator Agent**: Routes queries to appropriate sub-agents
5. **Context Agent**: Asks for clarification when program/level is ambiguous
6. **Web UI**: Google ADK provides built-in web interface for testing

### Agent Orchestration Flow

1. **Query Reception**: User asks natural language question
2. **Orchestrator Routing**: Determines which sub-agent can best answer
3. **Context Clarification**: If needed, asks user for program/level specification
4. **Sub-Agent Processing**: Relevant agent queries ChromaDB for context
5. **Response Generation**: Agent provides context-aware answer using RAG
6. **User Interaction**: Response delivered through web UI

## ðŸ“Š Data Pipeline Output

### Content Organization

```
outputs/
â”œâ”€â”€ ds/                     # Data Science Program
â”‚   â”œâ”€â”€ foundation/         # Foundation Level
â”‚   â”‚   â””â”€â”€ content.txt     # ~50k-100k characters
â”‚   â”œâ”€â”€ diploma/            # Diploma Level
â”‚   â”‚   â””â”€â”€ content.txt     # ~100k-150k characters
â”‚   â””â”€â”€ degree/             # Degree Level
â”‚       â””â”€â”€ content.txt     # ~150k-200k characters
â””â”€â”€ es/                     # Electronics Systems Program
    â”œâ”€â”€ foundation/         # Foundation Level
    â”‚   â””â”€â”€ content.txt     # ~50k-100k characters
    â”œâ”€â”€ diploma/            # Diploma Level
    â”‚   â””â”€â”€ content.txt     # ~100k-150k characters
    â””â”€â”€ degree/             # Degree Level
        â””â”€â”€ content.txt     # ~150k-200k characters
```

### ChromaDB Collections

-   **Collection Names**: `{program}_{level}` (e.g., `ds_foundation`, `es_diploma`)
-   **Embeddings**: Google Gemini `gemini-embedding-001` (768 dimensions)
-   **Content Range**: 50k to 2 lakh characters per collection
-   **Total Content**: 7+ lakh characters across all collections

## ðŸŽ¯ Use Cases

### Current Capabilities

-   **Daily Data Updates**: Automated scraping and processing of 127+ IITM pages
-   **Hierarchical Content Organization**: Structured storage by program and level
-   **Enhanced Semantic Search**: Advanced ChromaDB querying with smart_query, program/level filtering
-   **Complete DS Agent Suite**: All three DS agents (Foundation, Diploma, Degree) fully implemented
-   **Chunked Data Processing**: Improved retrieval precision with similarity scoring
-   **Web Interface**: Google ADK built-in web UI for testing and interaction
-   **Context-Aware Responses**: RAG-powered answers with relevant course information
-   **Metadata-Rich Queries**: Access to course IDs, URLs, and chunk information

### AI Agent Capabilities

-   **DS Foundation Agent**: Specialized knowledge for foundational Data Science concepts and courses
-   **DS Diploma Agent**: Expertise in both Diploma in Programming and Diploma in Data Science tracks
-   **DS Degree Agent**: Advanced knowledge for degree-level Data Science courses and requirements
-   **Enhanced ChromaDB Integration**: Smart querying across multiple collections with automatic routing
-   **Advanced RAG Pipeline**: Context-aware responses using chunked data and similarity scoring
-   **Natural Language Processing**: Understands complex academic queries with level-specific context
-   **Program-Specific Knowledge**: Specialized knowledge for each academic level and program track

### Example Queries

**Foundation Level:**

-   "What courses should I take in my next term for DS foundation level?"
-   "Which foundation courses are most important for data science?"
-   "What are the prerequisites for foundation level courses?"

**Diploma Level:**

-   "What's the difference between Diploma in Programming and Diploma in Data Science?"
-   "Which diploma courses should I take after completing foundation?"
-   "What are the requirements for diploma level courses?"

**Degree Level:**

-   "What are the prerequisites for BSDA1001?"
-   "Which degree level courses are most challenging?"
-   "What's the difference between DS and ES foundation courses?"

## ðŸš€ Next Steps

### Immediate Development

-   **ES Agent Suite**: Complete Electronics Systems agents (Foundation, Diploma, Degree levels)
-   **Orchestrator Agent**: Central agent to route queries to appropriate sub-agents
-   **Context Agent**: Agent to ask for clarification when program/level is ambiguous
-   **Enhanced Web UI**: Improved user interface for better interaction
-   **Cross-Program Queries**: Agents that can answer questions spanning multiple programs

### Future Enhancements

-   **Advanced Analytics**: Course difficulty analysis and success prediction
-   **Integration APIs**: REST APIs for external system integration
-   **Mobile Interface**: Mobile-optimized student interface
-   **Real-time Updates**: Dynamic data source updates and synchronization
-   **Multi-Program Orchestration**: Unified interface for DS and ES program queries

This system enables building:

-   Intelligent course recommendation systems with AI agents
-   Academic planning assistants with context-aware responses
-   Prerequisite validation tools with semantic search
-   Curriculum analysis dashboards with hierarchical data
-   Multi-agent educational platforms with orchestrated sub-agents
